{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d2b5c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kyana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kyana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kyana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Load necessary resources\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2edecc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mcdonald food ok service bad', 'would recommend japanese restaurant anyone', 'loved restaurant traveled thailand last summer', 'menu loving wide variety option', 'staff friendly helpful google employee restaurant', 'ambiance bella italia amazing pasta dish delicious', 'terrible experience pizza hut pizza burnt service slow', 'sushi sushi express always fresh flavorful', 'steakhouse main street cozy atmosphere excellent steak', 'dessert selection sweet treat die']\n"
     ]
    }
   ],
   "source": [
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess_text(data):\n",
    "    preprocessed_data = []\n",
    "    for review in data['Review']:\n",
    "        # Convert to lowercase\n",
    "        review = review.lower()\n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(review)\n",
    "        # Remove punctuation\n",
    "        tokens = [word for word in tokens if word.isalnum()]\n",
    "        # Lemmatize\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "        preprocessed_data.append(' '.join(tokens))\n",
    "    return preprocessed_data\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'Review': [\n",
    "        'At McDonald\\'s the food was ok and the service was bad.',\n",
    "        'I would not recommend this Japanese restaurant to anyone.',\n",
    "        'I loved this restaurant when I traveled to Thailand last summer.',\n",
    "        'The menu of Loving has a wide variety of options.',\n",
    "        'The staff was friendly and helpful at Google\\'s employees restaurant.',\n",
    "        'The ambiance at Bella Italia is amazing, and the pasta dishes are delicious.',\n",
    "        'I had a terrible experience at Pizza Hut. The pizza was burnt, and the service was slow.',\n",
    "        'The sushi at Sushi Express is always fresh and flavorful.',\n",
    "        'The steakhouse on Main Street has a cozy atmosphere and excellent steaks.',\n",
    "        'The dessert selection at Sweet Treats is to die for!'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Apply the preprocess_text function and print the result\n",
    "preprocessed_data = preprocess_text(data)\n",
    "print(preprocessed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a829995f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  \\\n",
      "0  At McDonald's the food was ok and the service ...   \n",
      "1  I would not recommend this Japanese restaurant...   \n",
      "2  I loved this restaurant when I traveled to Tha...   \n",
      "3  The menu of Loving has a wide variety of options.   \n",
      "4  The staff was friendly and helpful at Google's...   \n",
      "5  The ambiance at Bella Italia is amazing, and t...   \n",
      "6  I had a terrible experience at Pizza Hut. The ...   \n",
      "7  The sushi at Sushi Express is always fresh and...   \n",
      "8  The steakhouse on Main Street has a cozy atmos...   \n",
      "9  The dessert selection at Sweet Treats is to di...   \n",
      "\n",
      "                                      Cleaned_Review  \n",
      "0                       mcdonald food ok service bad  \n",
      "1         would recommend japanese restaurant anyone  \n",
      "2     loved restaurant traveled thailand last summer  \n",
      "3                    menu loving wide variety option  \n",
      "4  staff friendly helpful google employee restaurant  \n",
      "5  ambiance bella italia amazing pasta dish delic...  \n",
      "6  terrible experience pizza hut pizza burnt serv...  \n",
      "7         sushi sushi express always fresh flavorful  \n",
      "8  steakhouse main street cozy atmosphere excelle...  \n",
      "9                  dessert selection sweet treat die  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a new dataset with the cleaned text\n",
    "cleaned_data = pd.DataFrame({\n",
    "    'Review': data['Review'],\n",
    "    'Cleaned_Review': preprocessed_data\n",
    "})\n",
    "print(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f1ffc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [(mcdonald food ok service, ORG)]\n",
      "1                        [(japanese, NORP)]\n",
      "2    [(thailand, GPE), (last summer, DATE)]\n",
      "3                                        []\n",
      "4                           [(google, ORG)]\n",
      "5            [(ambiance bella italia, ORG)]\n",
      "6                                        []\n",
      "7           [(sushi sushi express, PERSON)]\n",
      "8                                        []\n",
      "9                                        []\n",
      "Name: Cleaned_Review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def perform_ner(text):\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "# Apply the perform_ner function and print the results\n",
    "ner_results = cleaned_data['Cleaned_Review'].apply(perform_ner)\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4830995d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kyana\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [(mcdonald, NNS), (food, NN), (ok, JJ), (servi...\n",
      "1    [(would, MD), (recommend, VB), (japanese, JJ),...\n",
      "2    [(loved, VBN), (restaurant, NN), (traveled, VB...\n",
      "3    [(menu, NN), (loving, VBG), (wide, JJ), (varie...\n",
      "4    [(staff, NN), (friendly, RB), (helpful, JJ), (...\n",
      "5    [(ambiance, NN), (bella, NN), (italia, NN), (a...\n",
      "6    [(terrible, JJ), (experience, NN), (pizza, NN)...\n",
      "7    [(sushi, NN), (sushi, NN), (express, NN), (alw...\n",
      "8    [(steakhouse, NN), (main, JJ), (street, NN), (...\n",
      "9    [(dessert, JJ), (selection, NN), (sweet, JJ), ...\n",
      "Name: Cleaned_Review, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def perform_pos_tagging(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    return pos_tags\n",
    "\n",
    "# Apply the perform_pos_tagging function and print the results\n",
    "pos_results = cleaned_data['Cleaned_Review'].apply(perform_pos_tagging)\n",
    "print(pos_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ca07110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  \\\n",
      "0  At McDonald's the food was ok and the service ...   \n",
      "1  I would not recommend this Japanese restaurant...   \n",
      "2  I loved this restaurant when I traveled to Tha...   \n",
      "3  The menu of Loving has a wide variety of options.   \n",
      "4  The staff was friendly and helpful at Google's...   \n",
      "5  The ambiance at Bella Italia is amazing, and t...   \n",
      "6  I had a terrible experience at Pizza Hut. The ...   \n",
      "7  The sushi at Sushi Express is always fresh and...   \n",
      "8  The steakhouse on Main Street has a cozy atmos...   \n",
      "9  The dessert selection at Sweet Treats is to di...   \n",
      "\n",
      "                                      Cleaned_Review  \\\n",
      "0                       mcdonald food ok service bad   \n",
      "1         would recommend japanese restaurant anyone   \n",
      "2     loved restaurant traveled thailand last summer   \n",
      "3                    menu loving wide variety option   \n",
      "4  staff friendly helpful google employee restaurant   \n",
      "5  ambiance bella italia amazing pasta dish delic...   \n",
      "6  terrible experience pizza hut pizza burnt serv...   \n",
      "7         sushi sushi express always fresh flavorful   \n",
      "8  steakhouse main street cozy atmosphere excelle...   \n",
      "9                  dessert selection sweet treat die   \n",
      "\n",
      "                                  NER_Raw  \\\n",
      "0                     [(McDonald's, ORG)]   \n",
      "1                      [(Japanese, NORP)]   \n",
      "2  [(Thailand, GPE), (last summer, DATE)]   \n",
      "3                         [(Loving, GPE)]   \n",
      "4                         [(Google, ORG)]   \n",
      "5                   [(Bella Italia, ORG)]   \n",
      "6                      [(Pizza Hut, ORG)]   \n",
      "7                  [(Sushi Express, ORG)]   \n",
      "8                    [(Main Street, FAC)]   \n",
      "9                   [(Sweet Treats, FAC)]   \n",
      "\n",
      "                              NER_Cleaned  \\\n",
      "0       [(mcdonald food ok service, ORG)]   \n",
      "1                      [(japanese, NORP)]   \n",
      "2  [(thailand, GPE), (last summer, DATE)]   \n",
      "3                                      []   \n",
      "4                         [(google, ORG)]   \n",
      "5          [(ambiance bella italia, ORG)]   \n",
      "6                                      []   \n",
      "7         [(sushi sushi express, PERSON)]   \n",
      "8                                      []   \n",
      "9                                      []   \n",
      "\n",
      "                                             POS_Raw  \\\n",
      "0  [(At, IN), (McDonald, NNP), ('s, POS), (the, D...   \n",
      "1  [(I, PRP), (would, MD), (not, RB), (recommend,...   \n",
      "2  [(I, PRP), (loved, VBD), (this, DT), (restaura...   \n",
      "3  [(The, DT), (menu, NN), (of, IN), (Loving, NNP...   \n",
      "4  [(The, DT), (staff, NN), (was, VBD), (friendly...   \n",
      "5  [(The, DT), (ambiance, NN), (at, IN), (Bella, ...   \n",
      "6  [(I, PRP), (had, VBD), (a, DT), (terrible, JJ)...   \n",
      "7  [(The, DT), (sushi, NN), (at, IN), (Sushi, NNP...   \n",
      "8  [(The, DT), (steakhouse, NN), (on, IN), (Main,...   \n",
      "9  [(The, DT), (dessert, JJ), (selection, NN), (a...   \n",
      "\n",
      "                                         POS_Cleaned  \n",
      "0  [(mcdonald, NNS), (food, NN), (ok, JJ), (servi...  \n",
      "1  [(would, MD), (recommend, VB), (japanese, JJ),...  \n",
      "2  [(loved, VBN), (restaurant, NN), (traveled, VB...  \n",
      "3  [(menu, NN), (loving, VBG), (wide, JJ), (varie...  \n",
      "4  [(staff, NN), (friendly, RB), (helpful, JJ), (...  \n",
      "5  [(ambiance, NN), (bella, NN), (italia, NN), (a...  \n",
      "6  [(terrible, JJ), (experience, NN), (pizza, NN)...  \n",
      "7  [(sushi, NN), (sushi, NN), (express, NN), (alw...  \n",
      "8  [(steakhouse, NN), (main, JJ), (street, NN), (...  \n",
      "9  [(dessert, JJ), (selection, NN), (sweet, JJ), ...  \n"
     ]
    }
   ],
   "source": [
    "# Apply NER and POS tagging to both raw and cleaned data\n",
    "cleaned_data['NER_Raw'] = cleaned_data['Review'].apply(perform_ner)\n",
    "cleaned_data['NER_Cleaned'] = cleaned_data['Cleaned_Review'].apply(perform_ner)\n",
    "cleaned_data['POS_Raw'] = cleaned_data['Review'].apply(perform_pos_tagging)\n",
    "cleaned_data['POS_Cleaned'] = cleaned_data['Cleaned_Review'].apply(perform_pos_tagging)\n",
    "\n",
    "# Print the dataset with NER and POS results\n",
    "print(cleaned_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
