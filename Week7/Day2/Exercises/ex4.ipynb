{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 : Scrape And Categorize News Articles From A JavaScript-Enabled News Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pprint  # To tidy up\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')  # Run Chrome in headless mode\n",
    "options.add_argument(\"--no-sandbox\")  # Bypass OS security model\n",
    "options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Function to scrape archive data from iranintl.com\n",
    "def scrape_page(url):\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html')\n",
    "    articles = soup.find_all('article')\n",
    "\n",
    "    data = []\n",
    "    for article in articles:\n",
    "        # Find the h3 element containing the article name\n",
    "        article_name = article.find('h3', class_='jsx-268a7bdb02dd195b card__headline')\n",
    "        if article_name:\n",
    "            article_name_text = article_name.get_text(strip=True)\n",
    "\n",
    "        # Find the time element containing the datetime\n",
    "        time_element = article.find('time')\n",
    "        if time_element:\n",
    "            datetime = time_element['datetime']\n",
    "\n",
    "        data.append({'Article_name': article_name_text, 'Article_date': datetime})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Function to scrape data from multiple pages\n",
    "def scrape_multiple_pages(base_url, max_pages):\n",
    "    all_data = []\n",
    "    for page_number in range(1, max_pages + 1):\n",
    "        url = f\"{base_url}/page/{page_number}\"\n",
    "        data = scrape_page(url)\n",
    "        all_data.extend(data)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Define the base URL and the maximum number of pages to scrape\n",
    "base_url = \"https://www.iranintl.com/en/archive/iran-en\"\n",
    "max_pages = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Scrape data from multiple pages\n",
    "all_data = scrape_multiple_pages(base_url, max_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Convert 'Article_date' to datetime format\n",
    "df1['Article_date'] = pd.to_datetime(df1['Article_date'].dt.date)\n",
    "\n",
    "# Create a new column with month names\n",
    "df1['Month'] = pd.to_datetime(df1['Article_date']).dt.strftime('%B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
